# Feature Plan: Add NVIDIA NIM Models with Image Support

## Overview

Add four new models to the NVIDIA NIM service and implement image/file attachment support for vision-capable models within the NVIDIA NIM service.

### New Models

| Display Name | API Model ID | Image Support |
|--------------|--------------|---------------|
| Kimi K2.5 | `moonshotai/kimi-k2.5` | Yes |
| GLM-4.7 | `z-ai/glm4.7` | No |
| GLM-5 | `z-ai/glm5` | No |
| Qwen3.5-397B-A17B | `qwen/qwen3.5-397b-a17b` | Yes |

### Existing Models (unchanged)

| Display Name | API Model ID | Image Support |
|--------------|--------------|---------------|
| DeepSeek V3.2 | `deepseek-ai/deepseek-v3.2` | No |
| Kimi K2 | `moonshotai/kimi-k2-thinking` | No |

---

## Files to Modify

### 1. `core/services/nvidia_nim_service.py`

**Changes Required:**

1. **Update `MODEL_MAP`** (line 66-69):
   - Add the four new model mappings

2. **Add model capability tracking**:
   - Add a `VISION_MODELS` set to track which models support images
   - Contains: `moonshotai/kimi-k2.5`, `qwen/qwen3.5-397b-a17b`

3. **Update `generate_response()` method** (line 93):
   - Add `files_data` parameter to accept file attachments
   - Build message content with image support for vision models
   - Use OpenAI SDK format for image content: `{"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{base64_data}"}}`

4. **Update `NvidiaNimWorker` class** (line 6):
   - Modify to handle multi-part message content (text + images)

**Image Message Format for NVIDIA NIM:**

Per the NVIDIA NIM API documentation, images are sent using OpenAI-compatible format:

```python
messages = [
    {
        "role": "user",
        "content": [
            {"type": "text", "text": "user text here"},
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image_data}"
                }
            }
        ]
    }
]
```

### 2. `gui/widgets/action_buttons_panel.py`

**Changes Required:**

1. **Update `SERVICE_MODELS`** (line 28-31):
   - Add the four new models to the NVIDIA NIM list

2. **Update `_update_file_controls_state()`** (line 303):
   - Change logic from service-level to model-level file support
   - Enable file attachment button only when current model supports images
   - Current logic disables files for all NVIDIA NIM models; new logic checks if model is in vision-capable list

3. **Add model capability tracking**:
   - Add `NVIDIA_VISION_MODELS` set containing: `"Kimi K2.5"`, `"Qwen3.5-397B-A17B"`

### 3. `app/controller.py`

**Changes Required:**

1. **Update `_process_message()`** (line 199):
   - Modify the condition that passes `files_data` to NVIDIA NIM service
   - Current code only passes files_data for Gemini (line 231-232)
   - New logic: pass files_data for NVIDIA NIM if the selected model supports images

2. **Add helper method or inline check**:
   - Determine if current NVIDIA NIM model supports images before passing files_data

### 4. `prompts.json` (not read directly)

**Changes Required:**
- Add system prompts for new models following existing pattern
- Keys: `NVIDIA NIM:Kimi K2.5`, `NVIDIA NIM:GLM-4.7`, `NVIDIA NIM:GLM-5`, `NVIDIA NIM:Qwen3.5-397B-A17B`
- Each key needs both `text` and `vision` prompts (vision only used for image-capable models)

---

## Implementation Details

### Phase 1: Data Layer - Model Definitions

1. Update `MODEL_MAP` in `nvidia_nim_service.py` with new models
2. Add `VISION_MODELS` set to track image-capable models
3. Update `SERVICE_MODELS` in `action_buttons_panel.py`
4. Add `NVIDIA_VISION_MODELS` set in `action_buttons_panel.py`

### Phase 2A: Service Layer - NVIDIA NIM Image Support

1. Modify `generate_response()` signature to accept `files_data` parameter
2. Implement message content building with image support
3. Handle multi-part content in worker thread

### Phase 2B: UI Layer - Conditional File Controls

1. Update `_update_file_controls_state()` to check model capabilities
2. Enable/disable file attachment based on selected model

### Phase 2C: Controller Layer - Request Routing

1. Update `_process_message()` to pass files_data for vision-capable NVIDIA NIM models
2. Add model capability check logic

---

## Key Algorithms

### Image Content Building for NVIDIA NIM

```
For each file in files_data:
    If file mime_type starts with "image/":
        Add image_url content part with base64 data
    Else:
        Reject or skip non-image files (NVIDIA NIM only supports images)

Build message content:
    If has images:
        content = [{"type": "text", "text": user_input}]
        For each image:
            content.append({"type": "image_url", "image_url": {"url": f"data:{mime};base64,{data}"}})
    Else:
        content = user_input (plain string)
```

### Model Capability Check

```
def model_supports_images(service: str, model: str) -> bool:
    If service == "Gemini":
        Return True  # All Gemini models support images
    Elif service == "NVIDIA NIM":
        Return model in NVIDIA_VISION_MODELS
    Return False
```

---

## Verbatim Requirements from User

1. **Model names from NVIDIA NIM website:**
   - `"model": "moonshotai/kimi-k2.5"`
   - `model="z-ai/glm5"`
   - `model="z-ai/glm4.7"`
   - `"model": "qwen/qwen3.5-397b-a17b"`

2. **Image support:** "The 'moonshotai/kimi-k2.5', and 'qwen/qwen3.5-397b-a17b', models support images via the API."

3. **Display names confirmed by user:**
   - Kimi K2.5
   - GLM-4.7
   - GLM-5
   - Qwen3.5-397B-A17B

4. **GLM models are text-only** (confirmed by user)

5. **Keep existing Kimi K2 alongside K2.5** (confirmed by user)

6. **All models support reasoning/streaming** (per user: "All models support reasoning / streaming")

---

## Testing Considerations

1. Verify file attachment button enables/disables correctly based on selected model
2. Test image upload and processing with Kimi K2.5 and Qwen3.5-397B-A17B
3. Verify text-only models reject file attachments appropriately
4. Test streaming and thinking/reasoning output for all new models
5. Verify model selection persists correctly in gui_config.json
